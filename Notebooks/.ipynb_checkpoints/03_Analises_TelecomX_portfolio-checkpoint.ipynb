{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 6. Correlação e Seleção de Variáveis\n\nEste bloco calcula a correlação entre variáveis numéricas e o alvo binário (point-biserial), exibe um ranking e plota um gráfico com as Top-N."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Bibliotecas utilizadas no projeto\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pointbiserialr\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix, classification_report\n)\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as ImbPipeline\n\nimport joblib\nfrom collections import OrderedDict\nfrom IPython.display import Markdown, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# === Correlação (alvo binário x numéricas) ===\n\n# 1) Descobrir o DataFrame base\ndef _guess_df(globs):\n    candidates = [\"df\", \"df_base\", \"dados\", \"data\", \"df_analise\", \"df_tratado\"]\n    for c in candidates:\n        if c in globs and isinstance(globs[c], pd.DataFrame):\n            return globs[c], c\n    paths = []\n    for pat in [\"data/*.csv\", \"*.csv\", \"datasets/*.csv\"]:\n        paths.extend(glob.glob(pat))\n    pref = [p for p in paths if any(k in os.path.basename(p).lower() for k in [\"telecom\", \"churn\", \"evas\", \"cliente\"])]\n    candidate_paths = pref + paths\n    for p in candidate_paths:\n        try:\n            _df = pd.read_csv(p)\n            return _df, f\"loaded_from_{p}\"\n        except Exception:\n            continue\n    raise RuntimeError(\"Não foi possível localizar o DataFrame. Garanta que uma variável do tipo DataFrame esteja definida (ex.: df).\")\n\ndf, df_name = _guess_df(globals())\n\n# 2) Identificar coluna-alvo (binária)\ndef _guess_target(_df):\n    target_names = [\"Evasao\",\"Evasão\",\"Churn\",\"churn\",\"evadiu\",\"cancelou\",\"saida\",\"Exited\",\"Attrition\"]\n    cols_lower = {c.lower(): c for c in _df.columns}\n    for name in target_names:\n        if name in _df.columns:\n            return name\n        if name.lower() in cols_lower:\n            return cols_lower[name.lower()]\n    bin_candidates = [c for c in _df.columns if _df[c].dropna().nunique() == 2]\n    if len(bin_candidates) == 1:\n        return bin_candidates[0]\n    raise RuntimeError(\"Não foi possível identificar a coluna alvo. Renomeie/defina explicitamente a variável alvo (ex.: 'Evasao').\")\n\ntarget_col = _guess_target(df)\n\n# 3) Garantir que o alvo esteja binário {0,1}\ny_raw = df[target_col].copy()\nif y_raw.dtype == bool:\n    y = y_raw.astype(int)\nelif y_raw.dtype.kind in \"biu\":\n    vals = sorted(pd.Series(y_raw.dropna().unique()).tolist())\n    if set(vals).issubset({0,1}):\n        y = y_raw.astype(int)\n    else:\n        most, least = pd.Series(vals).value_counts().index[:2].tolist()\n        y = (y_raw == least).astype(int)\nelse:\n    map_yes = {\"yes\",\"sim\",\"true\",\"churn\",\"evadiu\",\"cancelou\",\"s\",\"1\"}\n    y = y_raw.astype(str).str.strip().str.lower().map(lambda v: 1 if v in map_yes else 0)\n\n# 4) Selecionar numéricas (antes de encoding, se disponível)\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nif target_col in num_cols:\n    num_cols.remove(target_col)\n\nif len(num_cols) == 0:\n    raise RuntimeError(\"Não há colunas numéricas detectadas para calcular correlação.\")\n\n# 5) Correlação point-biserial alvo (binário) vs cada numérica\nrows = []\nfor c in num_cols:\n    x = pd.to_numeric(df[c], errors=\"coerce\")\n    mask = (~pd.isna(x)) & (~pd.isna(y))\n    if mask.sum() < 10:\n        continue\n    r, p = pointbiserialr(y[mask], x[mask])\n    rows.append({\"feature\": c, \"pointbiserial_r\": r, \"p_value\": p, \"abs_r\": abs(r)})\n\ncorr_df = pd.DataFrame(rows).sort_values(\"abs_r\", ascending=False).reset_index(drop=True)\n\ndisplay(corr_df.head(20))\n\n# 6) Plot Top-N correlações (|r|)\nTOPN = 15\ntop = corr_df.head(TOPN)\nplt.figure(figsize=(10, max(4, TOPN*0.35)))\nplt.barh(top[\"feature\"][::-1], top[\"abs_r\"][::-1])\nplt.title(f\"Top-{TOPN} | Correlação (|Point-Biserial r|) com {target_col}\")\nplt.xlabel(\"|r|\")\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 7. Análises Direcionadas\n\nVisualizações focadas na relação com a evasão: boxplots das variáveis mais correlacionadas e dispersões `tenure x MonthlyCharges`. Se não houver TotalCharges, cria-se `TotalCharges_calc = MonthlyCharges * tenure` (apenas para análise)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n\nassert 'df' in globals() and 'target_col' in globals()\n\ny_plot = df[target_col].copy()\nif y_plot.dtype != 'int64' and y_plot.dtype != 'int32':\n    map_yes = {\"yes\",\"sim\",\"true\",\"churn\",\"evadiu\",\"cancelou\",\"s\",\"1\"}\n    y_plot = y_plot.astype(str).str.strip().str.lower().map(lambda v: 1 if v in map_yes else 0).fillna(0).astype(int)\n\ndf_plot = df.copy()\ndf_plot[\"_alvo_bin\"] = y_plot\n\nnum_top = []\nif 'corr_df' in globals() and not corr_df.empty:\n    num_top = corr_df['feature'].tolist()[:2]\nelse:\n    num_cols = df_plot.select_dtypes(include=[np.number]).columns.tolist()\n    if target_col in num_cols: \n        num_cols.remove(target_col)\n    var_order = df_plot[num_cols].var().sort_values(ascending=False).index.tolist()\n    num_top = var_order[:2]\n\nfor c in num_top:\n    plt.figure(figsize=(7,4))\n    data0 = df_plot.loc[df_plot[\"_alvo_bin\"]==0, c].dropna().values\n    data1 = df_plot.loc[df_plot[\"_alvo_bin\"]==1, c].dropna().values\n    plt.boxplot([data0, data1], labels=[\"Sem Evasão (0)\",\"Com Evasão (1)\"], showmeans=True)\n    plt.title(f\"Boxplot de {c} por Evasão\")\n    plt.ylabel(c)\n    plt.tight_layout()\n    plt.show()\n\nx_name, y_name = None, None\nfor cand in [\"tenure\",\"TempoContrato\",\"tempo_contrato\",\"meses\"]:\n    if cand in df_plot.columns:\n        x_name = cand\n        break\nfor cand in [\"MonthlyCharges\",\"CobrancaMensal\",\"mensalidade\",\"mensal\"]:\n    if cand in df_plot.columns:\n        y_name = cand\n        break\n\nif x_name and y_name:\n    plt.figure(figsize=(7,5))\n    m0 = df_plot[\"_alvo_bin\"] == 0\n    m1 = df_plot[\"_alvo_bin\"] == 1\n    plt.scatter(df_plot.loc[m0, x_name], df_plot.loc[m0, y_name], alpha=0.4, label=\"Sem Evasão (0)\")\n    plt.scatter(df_plot.loc[m1, x_name], df_plot.loc[m1, y_name], alpha=0.4, label=\"Com Evasão (1)\")\n    plt.xlabel(x_name)\n    plt.ylabel(y_name)\n    plt.title(f\"Dispersão: {x_name} x {y_name} por Evasão\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\ntotal_name = None\nfor cand in [\"TotalCharges\",\"TotalGasto\",\"GastoTotal\",\"Fatura_Total\"]:\n    if cand in df_plot.columns:\n        total_name = cand\n        break\n\nif total_name is None and x_name and y_name:\n    df_plot[\"TotalCharges_calc\"] = pd.to_numeric(df_plot[y_name], errors=\"coerce\") * pd.to_numeric(df_plot[x_name], errors=\"coerce\")\n    total_name = \"TotalCharges_calc\"\n\nif total_name:\n    plt.figure(figsize=(7,4))\n    data0 = df_plot.loc[df_plot[\"_alvo_bin\"]==0, total_name].dropna().values\n    data1 = df_plot.loc[df_plot[\"_alvo_bin\"]==1, total_name].dropna().values\n    plt.boxplot([data0, data1], labels=[\"Sem Evasão (0)\",\"Com Evasão (1)\"], showmeans=True)\n    plt.title(f\"Boxplot de {total_name} por Evasão\")\n    plt.ylabel(total_name)\n    plt.tight_layout()\n    plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 9. Diagnóstico de Overfitting / Underfitting\n\nCompara validação cruzada (treino) x desempenho no teste do modelo final, com deltas e interpretação automática."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n\n\nwarnings.filterwarnings(\"ignore\")\n\nbest_pipe = None\nX_train = X_test = y_train = y_test = None\n\npossible_model_paths = [\n    \"artefatos/modelo_final.pkl\",\n    \"artefatos/pipeline_final.pkl\",\n    \"artefatos/modelo_rf.pkl\",\n    \"artefatos/best_model.pkl\",\n    \"model/pipeline_final.pkl\",\n]\npossible_data_paths = [\n    (\"artefatos/X_train.pkl\",\"artefatos/y_train.pkl\",\"artefatos/X_test.pkl\",\"artefatos/y_test.pkl\"),\n]\n\ntry:\n    for p in possible_model_paths:\n        if os.path.exists(p):\n            best_pipe = joblib.load(p)\n            break\n    if best_pipe is None:\n        if \"best_model\" in globals():\n            best_pipe = globals()[\"best_model\"]\n        elif \"final_model\" in globals():\n            best_pipe = globals()[\"final_model\"]\nexcept Exception:\n    pass\n\ntry:\n    for (a,b,c,d) in possible_data_paths:\n        if a and os.path.exists(a):\n            X_train = joblib.load(a)\n            y_train = joblib.load(b) if b and os.path.exists(b) else None\n            X_test  = joblib.load(c) if c and os.path.exists(c) else None\n            y_test  = joblib.load(d) if d and os.path.exists(d) else None\n            break\nexcept Exception:\n    pass\n\nif X_train is None or y_train is None:\n    if 'df' in globals() and 'target_col' in globals():\n        y_all = globals()['df'][target_col]\n        X_all = globals()['df'].drop(columns=[target_col])\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n        )\n\nif best_pipe is None:\n    raise RuntimeError(\"Não foi possível localizar o pipeline/modelo final. Ex.: 'best_model' ou .pkl em artefatos/.\")\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscoring = {\"acc\":\"accuracy\",\"prec\":\"precision\",\"rec\":\"recall\",\"f1\":\"f1\",\"roc\":\"roc_auc\"}\ncv_res = cross_validate(best_pipe, X_train, y_train, scoring=scoring, cv=cv, n_jobs=-1, return_train_score=False)\n\ncv_mean = {k: float(np.mean(v)) for k,v in cv_res.items() if k.startswith(\"test_\")}\ncv_tbl = pd.DataFrame({k.replace(\"test_\",\"CV_\"+k.split(\"_\",1)[1]): [v] for k,v in cv_mean.items()})\n\nbest_pipe.fit(X_train, y_train)\ny_pred = best_pipe.predict(X_test)\ny_proba = None\nif hasattr(best_pipe, \"predict_proba\"):\n    y_proba = best_pipe.predict_proba(X_test)[:,1]\nelse:\n    try:\n        y_proba = best_pipe.decision_function(X_test)\n    except Exception:\n        pass\n\ntest_metrics = {\n    \"TEST_acc\": accuracy_score(y_test, y_pred),\n    \"TEST_prec\": precision_score(y_test, y_pred, zero_division=0),\n    \"TEST_rec\": recall_score(y_test, y_pred, zero_division=0),\n    \"TEST_f1\": f1_score(y_test, y_pred, zero_division=0),\n}\nif y_proba is not None:\n    try:\n        test_metrics[\"TEST_roc\"] = roc_auc_score(y_test, y_proba)\n    except Exception:\n        pass\ntest_tbl = pd.DataFrame([test_metrics])\n\ncomp = pd.concat([cv_tbl, test_tbl], axis=1)\ndisplay(comp.T)\n\ndef _interp(row):\n    msgs = []\n    for met in [\"acc\",\"prec\",\"rec\",\"f1\",\"roc\"]:\n        cv_key = \"CV_\"+met\n        t_key = \"TEST_\"+met\n        if cv_key in row and t_key in row and pd.notna(row[cv_key]) and pd.notna(row[t_key]):\n            delta = row[t_key] - row[cv_key]\n            msgs.append(f\"{met.upper()}: TEST - CV = {delta:.4f}\")\n    if msgs:\n        print(\"\\n\".join(msgs))\n    if \"CV_f1\" in row and \"TEST_f1\" in row:\n        diff = row[\"TEST_f1\"] - row[\"CV_f1\"]\n        if diff < -0.03:\n            print(\"\\nPossível OVERFITTING: teste abaixo da média de CV.\")\n        elif diff > 0.03:\n            print(\"\\nPossível UNDERFITTING (ou CV pessimista): teste acima da média de CV.\")\n        else:\n            print(\"\\nGeneralização consistente: CV ~ Teste.\")\n            \n_interp(comp.iloc[0])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 10. Conclusão Estratégica\n\nGera um sumário auto-preenchido com os principais fatores (Top-10) e sugestões de retenção heurísticas, além de recomendações operacionais.\n- 6. Correlação e Seleção de Variáveis\n- 7. Análises Direcionadas\n- 9. Diagnóstico de Overfitting / Underfitting\n- 10. Conclusão Estratégica"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n\nif 'best_pipe' not in globals():\n    raise RuntimeError(\"O modelo final 'best_pipe' não está disponível. Rode o bloco anterior (over/underfitting).\")\n\nfeature_names = None\ntry:\n    set_config(transform_output=\"default\")\n    if hasattr(best_pipe, \"named_steps\"):\n        pre = best_pipe.named_steps.get(\"preprocess\") or best_pipe.named_steps.get(\"preprocessor\")\n        if pre is not None and hasattr(pre, \"get_feature_names_out\"):\n            feature_names = pre.get_feature_names_out()\nexcept Exception:\n    pass\n\nimportances = None\nmodel = best_pipe\nif hasattr(model, \"named_steps\"):\n    for k in (\"clf\",\"model\",\"classifier\",\"final_estimator\"):\n        if k in model.named_steps:\n            est = model.named_steps[k]\n            break\n    else:\n        est = None\nelse:\n    est = model\n\nif est is not None:\n    if hasattr(est, \"feature_importances_\"):\n        importances = np.array(est.feature_importances_)\n    elif hasattr(est, \"coef_\"):\n        coef = est.coef_\n        if hasattr(coef, \"toarray\"):\n            coef = coef.toarray()\n        importances = np.mean(np.abs(coef), axis=0)\n\nranking = []\nif importances is not None and feature_names is not None and len(importances) == len(feature_names):\n    for n, v in zip(feature_names, importances):\n        ranking.append((n, float(v)))\nelif 'corr_df' in globals() and not corr_df.empty:\n    ranking = list(zip(corr_df['feature'].tolist(), corr_df['abs_r'].tolist()))\nelse:\n    X_try = globals().get('X_train', None)\n    if X_try is not None and isinstance(X_try, pd.DataFrame):\n        variances = X_try.var().sort_values(ascending=False)\n        ranking = list(zip(variances.index.tolist(), variances.values.tolist()))\n\nTOPN = 10\nranking = sorted(ranking, key=lambda x: x[1], reverse=True)[:TOPN]\n\nsuggestions = OrderedDict([\n    (\"contract|month\", \"Clientes com contrato mensal tendem a evadir. Ofereça **migração para anual** com benefícios.\"),\n    (\"tenure|tempo\", \"Clientes com **pouco tempo de casa** exigem **onboarding reforçado** e contatos proativos (90 dias).\"),\n    (\"charges|mensal\", \"Cobrança mensal alta -> ofereça **planos mais adequados** ou **bundles** com melhor custo-benefício.\"),\n    (\"internet|fiber|dsl\", \"Tipo de Internet influencia satisfação. **Monitore qualidade** e **oriente upgrade** quando viável.\"),\n    (\"techsupport|support|suporte\", \"Ausência de **suporte técnico** liga-se à evasão. Proponha **canal prioritário**.\"),\n    (\"payment|automatic|cartao|debito\", \"Incentive **débito automático**/cartão para reduzir fricção e atrasos.\"),\n    (\"dependents|partner|senior\", \"Perfis família/idade podem demandar **planos familiares** e comunicação segmentada.\"),\n    (\"phoneservice|multiplelines\", \"Reveja **pacotes de telefonia** e tarifas; alinhe oferta ao uso real.\"),\n])\n\ndef suggest_for_feature(name):\n    n = str(name).lower()\n    for k, msg in suggestions.items():\n        keys = k.split(\"|\")\n        if any(kk in n for kk in keys):\n            return msg\n    return \"Monitore em campanhas de **retenção segmentada** e teste ofertas A/B.\"\n\nlines = []\nlines.append(\"## 10.1 Principais fatores (Top-10)\")\nfor i, (feat, score) in enumerate(ranking, 1):\n    lines.append(f\"- **{i:02d}. {feat}** — relevância: {score:.4f}\")\n\nlines.append(\"\\n## 10.2 Estratégias de retenção sugeridas (heurísticas)\")\nalready = set()\nfor feat, _ in ranking:\n    s = suggest_for_feature(feat)\n    if s not in already:\n        lines.append(f\"- **{feat}:** {s}\")\n        already.add(s)\n\nlines.append(\"\"\"\n## 10.3 Recomendações operacionais\n- **Threshold:** se o custo de perder um cliente é alto, reduza o limiar para aumentar *recall* e acione **playbooks**.\n- **Playbook 7–14 dias:** contato proativo + oferta personalizada (upgrade, desconto temporário, bônus de fidelidade).\n- **Monitoração:** reentreinar o modelo trimestralmente; acompanhar *drift*; comparar **CV x produção**.\n\"\"\")\n\ndisplay(Markdown(\"\\n\".join(lines)))"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}