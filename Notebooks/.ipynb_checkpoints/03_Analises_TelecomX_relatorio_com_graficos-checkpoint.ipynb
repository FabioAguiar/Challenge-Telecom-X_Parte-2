{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b5af94",
   "metadata": {},
   "source": [
    "# üìë Notebook 3 ‚Äî Relat√≥rio Final com Gr√°ficos (Telecom X)\n",
    "\n",
    "## Objetivo\n",
    "Elaborar um relat√≥rio detalhado destacando os fatores que mais influenciam a **evas√£o (churn)**, com base nas vari√°veis selecionadas e no desempenho do **modelo exportado** no Notebook 2.  \n",
    "Identificar os principais fatores que afetam a evas√£o e **propor estrat√©gias de reten√ß√£o** com base nos resultados obtidos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432498c",
   "metadata": {},
   "source": [
    "## 1) Carregar artefatos do Notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "MODEL_PATH = \"artefatos/modelo_churn_telecomx.pkl\"\n",
    "ARTEFATOS_PATH = \"artefatos/artefatos_modelagem.pkl\"\n",
    "TESTSET_PATH = \"artefatos/conjunto_teste.pkl\"\n",
    "\n",
    "if not (os.path.exists(MODEL_PATH) and os.path.exists(ARTEFATOS_PATH) and os.path.exists(TESTSET_PATH)):\n",
    "    raise FileNotFoundError(\"N√£o encontrei os artefatos exportados. Rodar o Notebook 2 at√© a etapa de exporta√ß√£o.\")\n",
    "\n",
    "best_pipe = joblib.load(MODEL_PATH)\n",
    "artefatos = joblib.load(ARTEFATOS_PATH)\n",
    "teste = joblib.load(TESTSET_PATH)\n",
    "X_test, y_test = teste[\"X_test\"], teste[\"y_test\"]\n",
    "\n",
    "feature_names_saved = artefatos.get(\"feature_names\")\n",
    "importances_df_saved = artefatos.get(\"importances_df\")\n",
    "coefs_df_saved = artefatos.get(\"coefs_df\")\n",
    "\n",
    "print(\"Origem do melhor modelo:\", artefatos.get(\"origem_melhor_modelo\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986d8d9",
   "metadata": {},
   "source": [
    "## 2) Desempenho no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d87a2d",
   "metadata": {},
   "source": [
    "**Interpretar:** priorizar **recall** em churn (classe 1) para **reduzir falsos negativos** (n√£o deixar evadir), aceitando mais falsos positivos quando necess√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd146831",
   "metadata": {},
   "source": [
    "## 3) Matriz de confus√£o (gr√°fico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Matriz de Confus√£o ‚Äî Modelo Final')\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.xticks([0,1], ['N√£o Evas√£o (0)', 'Evas√£o (1)'])\n",
    "plt.yticks([0,1], ['N√£o Evas√£o (0)', 'Evas√£o (1)'])\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    plt.text(j, i, int(val), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a94fd",
   "metadata": {},
   "source": [
    "**Ler assim:** diagonal = acertos; fora da diagonal = erros.  \n",
    "**Atentar:** falsos negativos (1 previsto como 0) s√£o cr√≠ticos em churn; medir impacto operacional do threshold de decis√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27056354",
   "metadata": {},
   "source": [
    "## 4) Import√¢ncia por Permuta√ß√£o (p√≥s-OHE) ‚Äî Top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff17ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Detectar passo de pr√©-processamento\n",
    "pre_step_name = None\n",
    "for candidate in [\"pre\", \"preprocess\"]:\n",
    "    if candidate in best_pipe.named_steps:\n",
    "        pre_step_name = candidate\n",
    "        break\n",
    "if pre_step_name is None:\n",
    "    raise RuntimeError(\"N√£o encontrei o passo de pr√©-processamento ('pre' ou 'preprocess').\")\n",
    "\n",
    "pre = best_pipe.named_steps[pre_step_name]\n",
    "model = best_pipe.named_steps[\"model\"]\n",
    "\n",
    "# Transformar X_test para espa√ßo p√≥s-OHE\n",
    "X_test_trans = pre.transform(X_test)\n",
    "\n",
    "# Nomes p√≥s-OHE\n",
    "ohe = pre.named_transformers_[\"cat\"]\n",
    "num_names = np.array(pre.transformers_[0][2], dtype=object)\n",
    "cat_cols_ = pre.transformers_[1][2]\n",
    "cat_names = ohe.get_feature_names_out(cat_cols_)\n",
    "feature_names_perm = np.concatenate([num_names, cat_names])\n",
    "\n",
    "# Calcular permutation importance no estimador final\n",
    "perm = permutation_importance(\n",
    "    model, X_test_trans, y_test,\n",
    "    n_repeats=10, random_state=42, scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "perm_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feature_names_perm,\n",
    "        \"importance_mean\": perm.importances_mean,\n",
    "        \"importance_std\": perm.importances_std\n",
    "    })\n",
    "    .sort_values(\"importance_mean\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Plot Top-15 (matplotlib puro)\n",
    "top = 15\n",
    "plot_df = perm_df.head(top).iloc[::-1]\n",
    "fig = plt.figure()\n",
    "plt.barh(plot_df[\"feature\"], plot_df[\"importance_mean\"])\n",
    "plt.title(\"Top 15 Vari√°veis por Import√¢ncia (Permutation Importance)\")\n",
    "plt.xlabel(\"Import√¢ncia m√©dia (Œî F1)\")\n",
    "plt.ylabel(\"Vari√°vel\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "perm_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b89fde",
   "metadata": {},
   "source": [
    "**Import√¢ncia por permuta√ß√£o:** medir quanto a m√©trica (F1) piorar ao embaralhar uma feature.  \n",
    "**Interpretar:** quanto maior a barra, maior a contribui√ß√£o da vari√°vel para o desempenho do modelo no teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6e6dc",
   "metadata": {},
   "source": [
    "## 5) Fatores do modelo (import√¢ncias/coeficientes) ‚Äî opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ace89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Reconstruir nomes, se necess√°rio\n",
    "feature_names_model = feature_names_saved if feature_names_saved is not None else None\n",
    "if feature_names_model is None:\n",
    "    try:\n",
    "        feature_names_model = feature_names_perm  # j√° calculados acima\n",
    "    except NameError:\n",
    "        feature_names_model = None\n",
    "\n",
    "if isinstance(best_pipe.named_steps[\"model\"], RandomForestClassifier) and feature_names_model is not None:\n",
    "    importances = best_pipe.named_steps[\"model\"].feature_importances_\n",
    "    imp_df = (\n",
    "        pd.DataFrame({\"feature\": feature_names_model, \"importance\": importances})\n",
    "        .sort_values(\"importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # Plot Top-15 (matplotlib puro)\n",
    "    plot_df2 = imp_df.head(15).iloc[::-1]\n",
    "    fig = plt.figure()\n",
    "    plt.barh(plot_df2[\"feature\"], plot_df2[\"importance\"])\n",
    "    plt.title(\"Top 15 ‚Äî Import√¢ncia (Random Forest)\")\n",
    "    plt.xlabel(\"Import√¢ncia (impureza)\")\n",
    "    plt.ylabel(\"Vari√°vel\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    imp_df.head(20)\n",
    "\n",
    "elif isinstance(best_pipe.named_steps[\"model\"], LogisticRegression) and feature_names_model is not None:\n",
    "    coefs = best_pipe.named_steps[\"model\"].coef_.ravel()\n",
    "    coef_df = (\n",
    "        pd.DataFrame({\"feature\": feature_names_model, \"coef\": coefs})\n",
    "        .assign(abs_coef=lambda d: d[\"coef\"].abs())\n",
    "        .sort_values(\"abs_coef\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # Plot Top-15 |coef| (matplotlib puro)\n",
    "    plot_df3 = coef_df.head(15).iloc[::-1]\n",
    "    fig = plt.figure()\n",
    "    plt.barh(plot_df3[\"feature\"], plot_df3[\"abs_coef\"])\n",
    "    plt.title(\"Top 15 ‚Äî |Coef| (Logistic Regression)\")\n",
    "    plt.xlabel(\"|Coef|\")\n",
    "    plt.ylabel(\"Vari√°vel\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    coef_df.head(20)\n",
    "else:\n",
    "    print(\"Modelo n√£o √© RandomForest nem LogisticRegression ou n√£o foi poss√≠vel reconstruir feature_names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9928ad",
   "metadata": {},
   "source": [
    "**Ler assim:**  \n",
    "- **Random Forest:** import√¢ncia baseada na redu√ß√£o m√©dia de impureza.  \n",
    "- **Logistic Regression:** coeficiente positivo associar a **maior** probabilidade de churn; negativo associar a **menor** probabilidade.  \n",
    "**Cautela:** tratar como **associa√ß√£o**, n√£o causalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc9d9d",
   "metadata": {},
   "source": [
    "## 6) Recomenda√ß√µes de reten√ß√£o (a partir dos gr√°ficos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3d30c",
   "metadata": {},
   "source": [
    "- **Priorizar** clientes com **tenure baixo** e **contrato mensal** para **migrar** para 1‚Äì2 anos com incentivo.  \n",
    "- **Oferecer** **Suporte T√©cnico** e **Seguran√ßa Online** como benef√≠cio de fidelidade em perfis de alto risco.  \n",
    "- **Aprimorar** a jornada de **Fatura Digital** e **migrar** **Electronic check** para **autopay**.  \n",
    "- **Monitorar** a experi√™ncia de clientes em **fibra** e **priorizar** SLA onde houver degrada√ß√£o.  \n",
    "- **Calibrar** o **threshold** para **maximizar recall** com custo controlado de falsos positivos; **mensurar** convers√£o por segmento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacda0c1",
   "metadata": {},
   "source": [
    "## 7) Pr√≥ximos passos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de1dde",
   "metadata": {},
   "source": [
    "- **Avaliar** ROC-AUC e PR-AUC; **rodar** valida√ß√£o cruzada estratificada.  \n",
    "- **Calibrar** probabilidades (*CalibratedClassifierCV*) e **ajustar** o threshold ao custo de neg√≥cio.  \n",
    "- **Monitorar** *drift* e **re-treinar** periodicamente.  \n",
    "- **Enriquecer** dados com vari√°veis de **qualidade de servi√ßo**, **pre√ßo/promos** e **hist√≥rico de contato**."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
